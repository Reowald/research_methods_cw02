Canada’s largest airline has been ordered to pay compensation after its chatbot gave a customer inaccurate information, misleading him into buying a full-price ticket.

Air Canada came under further criticism for later attempting to distance itself from the error by claiming that the bot was “responsible for its own actions”.

Amid a broader push by companies to automate services, the case – the first of its kind in Canada – raises questions about the level of oversight companies have over the chat tools.

In 2022, Jake Moffatt contacted Air Canada to determine which documents were needed to qualify for a bereavement fare, and if refunds could be granted retroactively.

According to Moffat’s screenshot of a conversation with the chatbot, the British Columbia resident was told he could apply for the refund “within 90 days of the date your ticket was issued” by completing an online form.

Moffatt then booked tickets to and from Toronto to attend the funeral of a family member. But when he applied for a refund, Air Canada said bereavement rates did not apply to completed travel and pointed to the bereavement section of the company’s website.

skip past newsletter promotion Sign up to TechScape Free weekly newsletter Alex Hern's weekly dive in to how technology is shaping our lives Enter your email address Sign up Privacy Notice: Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Newsletters may contain info about charities, online ads, and content funded by outside parties. For more information see our Privacy Policy . We use Google reCaptcha to protect our website and the Google Privacy Policy and Terms of Service apply. after newsletter promotion

Air Canada later admitted to Moffatt, when confronted with a screenshot of the chatbot’s advice months later, that the bot had used “misleading words” in its advice. The airline told Moffatt it would update the chatbot.

Moffatt then sued for the fare difference, prompting Air Canada to issue what the tribunal member Christopher Rivers called a “remarkable submission” in its defense.

Air Canada argued that despite the error, the chatbot was a “separate legal entity” and thus was responsible for its actions.

“While a chatbot has an interactive component, it is still just a part of Air Canada’s website. It should be obvious to Air Canada that it is responsible for all the information on its website,” wrote Rivers. “It makes no difference whether the information comes from a static page or a chatbot.”

While Air Canada argued correct information was available on its website, Rivers said the company did “not explain why the webpage titled ‘Bereavement Travel’ was inherently more trustworthy” than its chatbot.

“There is no reason why Mr Moffatt should know that one section of Air Canada’s webpage is accurate, and another is not,” he wrote.

Air Canada must pay Moffatt C$650.88, the equivalent of the difference between what Moffatt paid for his flight and a discounted bereavement fare – as well as C$36.14 in pre-judgment interest and C$125 in fees.